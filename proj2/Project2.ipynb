{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import FloatTensor, LongTensor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Linear).__init__()\n",
    "\n",
    "        self.name = 'Linear'\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.weight = FloatTensor(in_features, out_features)\n",
    "        self.weight_grad = FloatTensor(in_features, out_features)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = FloatTensor(out_features)\n",
    "            self.bias_grad = FloatTensor(out_features)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            self.bias_grad = None\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.uniform_(-stdv, stdv)\n",
    "        self.weight_grad.fill_(0)\n",
    "        if self.bias is not None:\n",
    "            self.bias.uniform_(-stdv, stdv)\n",
    "            self.bias_grad.fill_(0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Y = X * W + b\n",
    "        self.input = input.clone()\n",
    "        if self.bias is not None:\n",
    "            return self.input.matmul(self.weight).add(self.bias)\n",
    "        else:\n",
    "            return self.input.matmul(self.weight)\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        # dW = X^T * dL/dY\n",
    "        self.weight_grad = self.input.t().matmul(gradwrtoutput)\n",
    "        # db = (dL/dY)^T * 1\n",
    "        if self.bias is not None:\n",
    "            self.bias_grad = gradwrtoutput.t().sum(1)\n",
    "        # dX = dL/dY * W^T\n",
    "        return gradwrtoutput.matmul(self.weight.t())\n",
    "\n",
    "    def param(self):\n",
    "        if self.bias is not None:\n",
    "            return [(self.weight, self.weight_grad),\n",
    "                    (self.bias, self.bias_grad)]\n",
    "        else:\n",
    "            return [(self.weight, self.weight_grad)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU).__init__()\n",
    "\n",
    "        self.name = 'ReLU'\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Y = max(0,X)\n",
    "        self.input = input.clone()\n",
    "        return self.input.mul(self.input.gt(0).float())\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        if self.input is not None:\n",
    "            return gradwrtoutput.mul(self.input.gt(0).float())\n",
    "        else:\n",
    "            print(\"Forward First\")\n",
    "            return None\n",
    "\n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super(Tanh).__init__()\n",
    "        self.name = 'Tanh'\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Y = (exp(X) - exp(-X))/(exp(X) + exp(-X))\n",
    "        self.input = input.clone()\n",
    "        return self.input.tanh()\n",
    "        # self.input.masked_fill_(self.input.gt(50), 50)  # prevent overflow\n",
    "        # return (self.input.exp() - self.input.mul(-1).exp()) / (self.input.exp() + self.input.mul(-1).exp())\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        # dY/dX = 4/(exp(x) + exp(-x))^2\n",
    "        if self.input is not None:\n",
    "            grad = 4. / (self.input.exp() + self.input.mul(-1).exp()).pow(2)\n",
    "            return gradwrtoutput.mul(grad)\n",
    "        else:\n",
    "            print(\"Forward First\")\n",
    "            return None\n",
    "\n",
    "    def param(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Module):\n",
    "    def __init__(self):\n",
    "        super(Sequential).__init__()\n",
    "        self.name = 'Sequential'\n",
    "        self.module_list = []\n",
    "\n",
    "    def add(self, *module):\n",
    "        for m in module:\n",
    "            self.module_list.append(m)\n",
    "\n",
    "    def forward(self, input):\n",
    "        module_input = input.clone()\n",
    "        for module in self.module_list:\n",
    "            module_output = module.forward(module_input)\n",
    "            module_input = module_output\n",
    "        return module_output\n",
    "\n",
    "    def backward(self, gradwrtoutput):\n",
    "        grad = gradwrtoutput\n",
    "        for module in self.module_list[::-1]:\n",
    "            grad = module.backward(grad)\n",
    "        # return grad\n",
    "\n",
    "    def param(self):\n",
    "        param_list = []\n",
    "        for module in self.module_list:\n",
    "            param_list.append(module.param())\n",
    "        return param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossMSE():\n",
    "    def __init__(self):\n",
    "        super(LossMSE).__init__()\n",
    "        self.name = 'LossMSE'\n",
    "\n",
    "    def calculate(self, predict_value, true_value):\n",
    "        self.predict_value = predict_value\n",
    "        self.true_value = true_value\n",
    "        self.loss = (self.predict_value - self.true_value).float().pow(2).mean()\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self):\n",
    "        return 2 * (self.predict_value - self.true_value).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(label):\n",
    "    n = label.size(0)\n",
    "    y = FloatTensor(n, 2)\n",
    "    y[:, 0] = 2*(0.5-label)\n",
    "    y[:, 1] = -y[:, 0]\n",
    "    return y.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = FloatTensor(1000, 2).uniform_(0, 1)\n",
    "y_train = onehot(X_train.sub(0.5).pow(2).sum(1).lt(1./2./math.pi).float())\n",
    "\n",
    "X_test = FloatTensor(1000, 2).uniform_(0, 1)\n",
    "y_test = onehot(X_test.sub(0.5).pow(2).sum(1).lt(1./2./math.pi).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "mu, std = X_train.mean(), X_train.std()\n",
    "X_train.sub_(mu).div_(std)\n",
    "X_test.sub_(mu).div_(std);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Linear(2, 25), ReLU(), Linear(25, 2), Tanh())\n",
    "model.add(Linear(2, 25), ReLU(), Linear(25, 25), ReLU(), Linear(25, 2), Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Train Error: 61.00%\n"
     ]
    }
   ],
   "source": [
    "train_output = model.forward(X_train)\n",
    "print(\"Before Train Error: {:.2%}\".format(train_output.max(1)[1].ne(y_train.max(1)[1]).sum()/train_output.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Begin Epoch 0 ********\n",
      "Epoch 0 Batch  0: 1.01, 48.00%\n",
      "Epoch 0 Batch  1: 1.22, 58.00%\n",
      "Epoch 0 Batch  2: 1.17, 48.00%\n",
      "Epoch 0 Batch  3: 1.08, 64.00%\n",
      "Epoch 0 Batch  4: 1.24, 50.00%\n",
      "Epoch 0 Batch  5: 0.97, 32.00%\n",
      "Epoch 0 Batch  6: 1.01, 50.00%\n",
      "Epoch 0 Batch  7: 0.98, 44.00%\n",
      "Epoch 0 Batch  8: 0.93, 30.00%\n",
      "Epoch 0 Batch  9: 0.94, 36.00%\n",
      "Epoch 0 Batch 10: 0.95, 44.00%\n",
      "Epoch 0 Batch 11: 0.96, 50.00%\n",
      "Epoch 0 Batch 12: 0.98, 46.00%\n",
      "Epoch 0 Batch 13: 0.97, 42.00%\n",
      "Epoch 0 Batch 14: 0.84, 34.00%\n",
      "Epoch 0 Batch 15: 0.97, 52.00%\n",
      "Epoch 0 Batch 16: 0.90, 52.00%\n",
      "Epoch 0 Batch 17: 1.11, 48.00%\n",
      "Epoch 0 Batch 18: 1.26, 52.00%\n",
      "Epoch 0 Batch 19: 0.87, 42.00%\n",
      "******** After Epoch 0 ********\n",
      "\n",
      "Loss: 0.80, Error: 29.50%\n",
      "\n",
      "******** Begin Epoch 1 ********\n",
      "Epoch 1 Batch  0: 0.71, 22.00%\n",
      "Epoch 1 Batch  1: 0.84, 34.00%\n",
      "Epoch 1 Batch  2: 0.94, 36.00%\n",
      "Epoch 1 Batch  3: 0.91, 36.00%\n",
      "Epoch 1 Batch  4: 1.07, 50.00%\n",
      "Epoch 1 Batch  5: 0.92, 36.00%\n",
      "Epoch 1 Batch  6: 1.12, 50.00%\n",
      "Epoch 1 Batch  7: 0.98, 32.00%\n",
      "Epoch 1 Batch  8: 0.62, 14.00%\n",
      "Epoch 1 Batch  9: 0.73, 32.00%\n",
      "Epoch 1 Batch 10: 0.65, 28.00%\n",
      "Epoch 1 Batch 11: 1.19, 48.00%\n",
      "Epoch 1 Batch 12: 1.41, 48.00%\n",
      "Epoch 1 Batch 13: 0.66, 18.00%\n",
      "Epoch 1 Batch 14: 0.53, 22.00%\n",
      "Epoch 1 Batch 15: 0.79, 36.00%\n",
      "Epoch 1 Batch 16: 0.68, 28.00%\n",
      "Epoch 1 Batch 17: 1.27, 48.00%\n",
      "Epoch 1 Batch 18: 1.17, 42.00%\n",
      "Epoch 1 Batch 19: 0.68, 24.00%\n",
      "******** After Epoch 1 ********\n",
      "\n",
      "Loss: 0.81, Error: 30.90%\n",
      "\n",
      "******** Begin Epoch 2 ********\n",
      "Epoch 2 Batch  0: 0.59, 26.00%\n",
      "Epoch 2 Batch  1: 0.55, 16.00%\n",
      "Epoch 2 Batch  2: 0.70, 24.00%\n",
      "Epoch 2 Batch  3: 0.44, 16.00%\n",
      "Epoch 2 Batch  4: 0.29, 10.00%\n",
      "Epoch 2 Batch  5: 0.54, 24.00%\n",
      "Epoch 2 Batch  6: 1.03, 38.00%\n",
      "Epoch 2 Batch  7: 0.68, 24.00%\n",
      "Epoch 2 Batch  8: 0.60, 22.00%\n",
      "Epoch 2 Batch  9: 1.03, 32.00%\n",
      "Epoch 2 Batch 10: 0.63, 22.00%\n",
      "Epoch 2 Batch 11: 1.12, 42.00%\n",
      "Epoch 2 Batch 12: 0.90, 36.00%\n",
      "Epoch 2 Batch 13: 0.94, 30.00%\n",
      "Epoch 2 Batch 14: 0.42, 14.00%\n",
      "Epoch 2 Batch 15: 0.45, 14.00%\n",
      "Epoch 2 Batch 16: 0.28, 10.00%\n",
      "Epoch 2 Batch 17: 0.44, 14.00%\n",
      "Epoch 2 Batch 18: 0.60, 26.00%\n",
      "Epoch 2 Batch 19: 1.16, 32.00%\n",
      "******** After Epoch 2 ********\n",
      "\n",
      "Loss: 0.50, Error: 16.50%\n",
      "\n",
      "******** Begin Epoch 3 ********\n",
      "Epoch 3 Batch  0: 0.29,  8.00%\n",
      "Epoch 3 Batch  1: 0.39, 16.00%\n",
      "Epoch 3 Batch  2: 0.42, 12.00%\n",
      "Epoch 3 Batch  3: 0.34, 12.00%\n",
      "Epoch 3 Batch  4: 0.41, 16.00%\n",
      "Epoch 3 Batch  5: 0.49, 18.00%\n",
      "Epoch 3 Batch  6: 0.64, 24.00%\n",
      "Epoch 3 Batch  7: 0.88, 30.00%\n",
      "Epoch 3 Batch  8: 0.53, 22.00%\n",
      "Epoch 3 Batch  9: 0.69, 22.00%\n",
      "Epoch 3 Batch 10: 0.47, 20.00%\n",
      "Epoch 3 Batch 11: 0.56, 20.00%\n",
      "Epoch 3 Batch 12: 0.57, 16.00%\n",
      "Epoch 3 Batch 13: 0.36, 12.00%\n",
      "Epoch 3 Batch 14: 0.34, 12.00%\n",
      "Epoch 3 Batch 15: 0.49, 16.00%\n",
      "Epoch 3 Batch 16: 0.35, 14.00%\n",
      "Epoch 3 Batch 17: 0.59, 24.00%\n",
      "Epoch 3 Batch 18: 0.91, 30.00%\n",
      "Epoch 3 Batch 19: 0.25, 10.00%\n",
      "******** After Epoch 3 ********\n",
      "\n",
      "Loss: 0.28, Error:  9.80%\n",
      "\n",
      "******** Begin Epoch 4 ********\n",
      "Epoch 4 Batch  0: 0.16,  4.00%\n",
      "Epoch 4 Batch  1: 0.30, 12.00%\n",
      "Epoch 4 Batch  2: 0.43, 12.00%\n",
      "Epoch 4 Batch  3: 0.23,  6.00%\n",
      "Epoch 4 Batch  4: 0.33, 10.00%\n",
      "Epoch 4 Batch  5: 0.34, 14.00%\n",
      "Epoch 4 Batch  6: 0.39, 12.00%\n",
      "Epoch 4 Batch  7: 0.31, 10.00%\n",
      "Epoch 4 Batch  8: 0.45, 12.00%\n",
      "Epoch 4 Batch  9: 0.49, 18.00%\n",
      "Epoch 4 Batch 10: 0.67, 26.00%\n",
      "Epoch 4 Batch 11: 0.50, 16.00%\n",
      "Epoch 4 Batch 12: 0.55, 18.00%\n",
      "Epoch 4 Batch 13: 0.46, 18.00%\n",
      "Epoch 4 Batch 14: 0.27,  6.00%\n",
      "Epoch 4 Batch 15: 0.17,  6.00%\n",
      "Epoch 4 Batch 16: 0.16,  6.00%\n",
      "Epoch 4 Batch 17: 0.28,  8.00%\n",
      "Epoch 4 Batch 18: 0.36, 14.00%\n",
      "Epoch 4 Batch 19: 0.56, 18.00%\n",
      "******** After Epoch 4 ********\n",
      "\n",
      "Loss: 0.26, Error:  9.00%\n",
      "\n",
      "******** Begin Epoch 5 ********\n",
      "Epoch 5 Batch  0: 0.20,  8.00%\n",
      "Epoch 5 Batch  1: 0.62, 22.00%\n",
      "Epoch 5 Batch  2: 0.44, 22.00%\n",
      "Epoch 5 Batch  3: 0.83, 22.00%\n",
      "Epoch 5 Batch  4: 0.27, 10.00%\n",
      "Epoch 5 Batch  5: 0.33, 12.00%\n",
      "Epoch 5 Batch  6: 0.42, 14.00%\n",
      "Epoch 5 Batch  7: 0.26, 12.00%\n",
      "Epoch 5 Batch  8: 0.30, 10.00%\n",
      "Epoch 5 Batch  9: 0.31, 12.00%\n",
      "Epoch 5 Batch 10: 0.25,  4.00%\n",
      "Epoch 5 Batch 11: 0.18,  4.00%\n",
      "Epoch 5 Batch 12: 0.22,  8.00%\n",
      "Epoch 5 Batch 13: 0.22,  6.00%\n",
      "Epoch 5 Batch 14: 0.18,  6.00%\n",
      "Epoch 5 Batch 15: 0.12,  4.00%\n",
      "Epoch 5 Batch 16: 0.17,  6.00%\n",
      "Epoch 5 Batch 17: 0.28,  8.00%\n",
      "Epoch 5 Batch 18: 0.22, 10.00%\n",
      "Epoch 5 Batch 19: 0.40, 14.00%\n",
      "******** After Epoch 5 ********\n",
      "\n",
      "Loss: 0.24, Error:  7.60%\n",
      "\n",
      "******** Begin Epoch 6 ********\n",
      "Epoch 6 Batch  0: 0.16,  6.00%\n",
      "Epoch 6 Batch  1: 0.22,  8.00%\n",
      "Epoch 6 Batch  2: 0.34, 12.00%\n",
      "Epoch 6 Batch  3: 0.76, 22.00%\n",
      "Epoch 6 Batch  4: 0.31,  8.00%\n",
      "Epoch 6 Batch  5: 0.25, 12.00%\n",
      "Epoch 6 Batch  6: 0.33, 14.00%\n",
      "Epoch 6 Batch  7: 0.44, 18.00%\n",
      "Epoch 6 Batch  8: 0.30, 16.00%\n",
      "Epoch 6 Batch  9: 0.20,  6.00%\n",
      "Epoch 6 Batch 10: 0.22,  6.00%\n",
      "Epoch 6 Batch 11: 0.14,  4.00%\n",
      "Epoch 6 Batch 12: 0.13,  4.00%\n",
      "Epoch 6 Batch 13: 0.15,  4.00%\n",
      "Epoch 6 Batch 14: 0.12,  4.00%\n",
      "Epoch 6 Batch 15: 0.20,  8.00%\n",
      "Epoch 6 Batch 16: 0.20,  8.00%\n",
      "Epoch 6 Batch 17: 0.06,  2.00%\n",
      "Epoch 6 Batch 18: 0.17,  6.00%\n",
      "Epoch 6 Batch 19: 0.21,  8.00%\n",
      "******** After Epoch 6 ********\n",
      "\n",
      "Loss: 0.17, Error:  6.10%\n",
      "\n",
      "******** Begin Epoch 7 ********\n",
      "Epoch 7 Batch  0: 0.02,  0.00%\n",
      "Epoch 7 Batch  1: 0.20,  6.00%\n",
      "Epoch 7 Batch  2: 0.77, 26.00%\n",
      "Epoch 7 Batch  3: 0.87, 24.00%\n",
      "Epoch 7 Batch  4: 0.17,  6.00%\n",
      "Epoch 7 Batch  5: 0.21,  8.00%\n",
      "Epoch 7 Batch  6: 0.20,  6.00%\n",
      "Epoch 7 Batch  7: 0.52, 16.00%\n",
      "Epoch 7 Batch  8: 0.25,  8.00%\n",
      "Epoch 7 Batch  9: 0.40, 16.00%\n",
      "Epoch 7 Batch 10: 0.20,  8.00%\n",
      "Epoch 7 Batch 11: 0.15,  4.00%\n",
      "Epoch 7 Batch 12: 0.20,  8.00%\n",
      "Epoch 7 Batch 13: 0.14,  4.00%\n",
      "Epoch 7 Batch 14: 0.12,  2.00%\n",
      "Epoch 7 Batch 15: 0.22,  8.00%\n",
      "Epoch 7 Batch 16: 0.07,  4.00%\n",
      "Epoch 7 Batch 17: 0.07,  2.00%\n",
      "Epoch 7 Batch 18: 0.25,  8.00%\n",
      "Epoch 7 Batch 19: 0.25,  8.00%\n",
      "******** After Epoch 7 ********\n",
      "\n",
      "Loss: 0.10, Error:  2.20%\n",
      "\n",
      "******** Begin Epoch 8 ********\n",
      "Epoch 8 Batch  0: 0.03,  0.00%\n",
      "Epoch 8 Batch  1: 0.16,  6.00%\n",
      "Epoch 8 Batch  2: 0.54, 24.00%\n",
      "Epoch 8 Batch  3: 0.91, 26.00%\n",
      "Epoch 8 Batch  4: 0.23, 10.00%\n",
      "Epoch 8 Batch  5: 0.29,  8.00%\n",
      "Epoch 8 Batch  6: 0.30, 14.00%\n",
      "Epoch 8 Batch  7: 0.74, 26.00%\n",
      "Epoch 8 Batch  8: 0.34, 10.00%\n",
      "Epoch 8 Batch  9: 0.43, 16.00%\n",
      "Epoch 8 Batch 10: 0.17,  6.00%\n",
      "Epoch 8 Batch 11: 0.14,  6.00%\n",
      "Epoch 8 Batch 12: 0.17,  4.00%\n",
      "Epoch 8 Batch 13: 0.30, 10.00%\n",
      "Epoch 8 Batch 14: 0.15,  4.00%\n",
      "Epoch 8 Batch 15: 0.20,  8.00%\n",
      "Epoch 8 Batch 16: 0.09,  4.00%\n",
      "Epoch 8 Batch 17: 0.07,  2.00%\n",
      "Epoch 8 Batch 18: 0.22,  6.00%\n",
      "Epoch 8 Batch 19: 0.21,  8.00%\n",
      "******** After Epoch 8 ********\n",
      "\n",
      "Loss: 0.10, Error:  3.10%\n",
      "\n",
      "******** Begin Epoch 9 ********\n",
      "Epoch 9 Batch  0: 0.03,  0.00%\n",
      "Epoch 9 Batch  1: 0.13,  4.00%\n",
      "Epoch 9 Batch  2: 0.29, 10.00%\n",
      "Epoch 9 Batch  3: 0.87, 24.00%\n",
      "Epoch 9 Batch  4: 0.25, 10.00%\n",
      "Epoch 9 Batch  5: 0.28,  8.00%\n",
      "Epoch 9 Batch  6: 0.18,  4.00%\n",
      "Epoch 9 Batch  7: 0.31, 10.00%\n",
      "Epoch 9 Batch  8: 0.16,  6.00%\n",
      "Epoch 9 Batch  9: 0.38, 12.00%\n",
      "Epoch 9 Batch 10: 0.19,  8.00%\n",
      "Epoch 9 Batch 11: 0.14,  6.00%\n",
      "Epoch 9 Batch 12: 0.10,  2.00%\n",
      "Epoch 9 Batch 13: 0.11,  2.00%\n",
      "Epoch 9 Batch 14: 0.13,  2.00%\n",
      "Epoch 9 Batch 15: 0.29, 10.00%\n",
      "Epoch 9 Batch 16: 0.06,  2.00%\n",
      "Epoch 9 Batch 17: 0.05,  0.00%\n",
      "Epoch 9 Batch 18: 0.24,  8.00%\n",
      "Epoch 9 Batch 19: 0.19,  8.00%\n",
      "******** After Epoch 9 ********\n",
      "\n",
      "Loss: 0.12, Error:  4.50%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "mini_batch_size = 50\n",
    "epoch = 10\n",
    "\n",
    "criterion = LossMSE()\n",
    "\n",
    "for e in range(epoch):\n",
    "    print(\"******** Begin Epoch {} ********\".format(e))\n",
    "    for b in range(0, X_train.size(0), mini_batch_size):\n",
    "        output = model.forward(X_train.narrow(0, b, mini_batch_size))\n",
    "        #print(output)\n",
    "        #predict = output.max(1)[1]\n",
    "        loss = criterion.calculate(output, y_train.narrow(0, b, mini_batch_size).float())\n",
    "        error = output.max(1)[1].ne(y_train.narrow(0, b, mini_batch_size).max(1)[1]).sum()/output.size(0)\n",
    "        print(\"Epoch {} Batch {:2.0f}: {:4.2f}, {:6.2%}\".format(e, b/mini_batch_size, loss, error))\n",
    "        l_grad = criterion.backward()\n",
    "        #print(l_grad)\n",
    "        model.backward(l_grad)\n",
    "        for layer in model.param():\n",
    "            for p in layer:\n",
    "                p[0].sub_(lr*p[1])\n",
    "    print(\"******** After Epoch {} ********\".format(e))\n",
    "    output = model.forward(X_train)\n",
    "    loss = criterion.calculate(output, y_train.float())\n",
    "    error = output.max(1)[1].ne(y_train.max(1)[1]).sum()/output.size(0)\n",
    "    print(\"\\nLoss: {:4.2f}, Error: {:6.2%}\\n\".format(loss, error))\n",
    "    #print(e, criterion.calculate(model.forward(X_train), y_train.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: 4.50%\n",
      "Test Error: 5.70%\n"
     ]
    }
   ],
   "source": [
    "train_output = model.forward(X_train)\n",
    "print(\"Train Error: {:.2%}\".format(train_output.max(1)[1].ne(y_train.max(1)[1]).sum()/train_output.size(0)))\n",
    "\n",
    "test_output = model.forward(X_test)\n",
    "print(\"Test Error: {:.2%}\".format(test_output.max(1)[1].ne(y_test.max(1)[1]).sum()/test_output.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
